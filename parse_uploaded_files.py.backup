#!/usr/bin/env python

import os
from os.path import basename

import modin.pandas as pd
import pandas as serialpd

from collections import Counter
from granatum_sdk import Granatum, guess_gene_id_type, biomart_col_dict, convert_gene_ids

import numpy as np
import gzip
import shutil
import gc
import sys
import json
import scipy

def main():
    gc.enable()
    gn = Granatum()

    assay_file = gn.get_uploaded_file_path("assayFile")
    sample_meta_file = gn.get_uploaded_file_path("sampleMetaFile")
    file_format = gn.get_arg("fileFormat")
    species = gn.get_arg("species")

    t = pd.SparseDtype(np.uint16, fill_value=0)
    # mat = []
    gene_ids = []

    if file_format == "gzip":
        print("Expanding file " + assay_file + " to " + assay_file + ".csv",  flush=True, file=sys.stderr)
        with gzip.open(assay_file, 'r') as f_in, open(assay_file+".csv", 'wb') as f_out:
            shutil.copyfileobj(f_in, f_out)
        assay_file = assay_file + ".csv"
        sz = os.path.getsize(assay_file)
        file_format = "csv"
        print("Expanded file has " + str(sz) + " bytes",  flush=True, file=sys.stderr)
        
    if file_format == "excel":
        tb = pd.read_excel(assay_file, index_col=0)
        # mat = tb.values.tolist(),
        gene_ids = tb.index.values.tolist()
    else:
        separator = " "
        if file_format == "csv":
            separator = ","
        elif file_format == "tsv":
            separator = "\t"

        print("Pulling column names",  flush=True, file=sys.stderr)
        colnames = pd.read_csv(assay_file, sep=separator, nrows=1).columns.tolist()
        usecoldict = {e1:"uint16" for e1 in colnames}
        usecoldict[colnames[0]] = "object"
        print("Extracted " + str(len(usecoldict)) + " column names",  flush=True, file=sys.stderr)

        i = 0
        tb = None
        for chunk in pd.read_csv(assay_file, sep=separator, index_col=0, dtype=usecoldict, chunksize=8E3):
            print("Chunk = " + str(i),  flush=True, file=sys.stderr)
            i = i+1
            # mat.extend(chunk.values.tolist())
            # print("Matrix is now "+str(len(mat))+" by "+str(len(mat[0])), file=sys.stderr)
            # gene_ids.extend(chunk.index.values.tolist())
            # print("Gene ids", flush=True, file=sys.stderr)
            # print(*gene_ids[0:5], sep=", ", flush=True, file=sys.stderr)
            if tb is None:
                tb = chunk.astype(t)
            else:
                tb = tb.append(chunk.astype(t))
            gc.collect()

    print("Entire array", flush=True, file=sys.stderr)
    print(str(tb),  flush=True, file=sys.stderr)
    print("Exporting assay now as complete pandas",  flush=True, file=sys.stderr)
    tb = gn.toser(tb)
    print("Entire array", flush=True, file=sys.stderr)
    print(str(tb),  flush=True, file=sys.stderr)
    exported_assay = tb
    # {
    #     "matrix": exp, # mat, # tb.values.tolist(),
    #     "sampleIds": sample_ids,
    #     "geneIds": gene_ids,
    #}

    print("Calling gn.export",  flush=True, file=sys.stderr)
    # gn.export(exported_assay, "[A]{}".format(basename(assay_file)), "assay")
    gn.export(exported_assay, "[A]{}".format(basename(assay_file)), "assay")
    print("gn.export completed",  flush=True, file=sys.stderr)

    print("Extracting sample_ids",  flush=True, file=sys.stderr)
    sample_ids = tb.columns.values.tolist()

    gene_id_type = guess_gene_id_type(gene_ids[:5])

    whether_convert_id = gn.get_arg("whether_convert_id")

    # if whether_convert_id:
    #     to_id_type = gn.get_arg("to_id_type")
    #     add_info = gn.get_arg("add_info")

    #     # if there are duplicated ids, pick the first row
    #     # TODO: Need to have a more sophisticated handling of duplicated ids

    #     gene_ids, new_meta = convert_gene_ids(gene_ids, gene_id_type, to_id_type, species, return_new_meta=True)

        # TODO: remove NaN rows
        # TODO: combine duplicated rows

    #     if add_info:
    #         for col_name, col in new_meta.iteritems():
    #             gn.export(col.to_dict(), col_name, "geneMeta")


    entry_preview = '\n'.join([', '.join(x) for x in tb.values[:10, :10].astype(str).tolist()])

    gn.add_result(
        f"""\
The assay has **{tb.shape[0]}** genes (with inferred ID type: {biomart_col_dict[gene_id_type]}) and **{tb.shape[1]}** samples.

The first few rows and columns:

```
{entry_preview}
```
""",
        "markdown",
    )

    meta_rows = []
    if sample_meta_file is not None:
        print("Checking meta file",  flush=True, file=sys.stderr)
        if file_format == "csv":
            sample_meta_tb = pd.read_csv(sample_meta_file)
        elif file_format == "tsv":
            sample_meta_tb = pd.read_csv(sample_meta_file, sep="\t")
        elif file_format == "excel":
            sample_meta_tb = pd.read_excel(sample_meta_file)
        else:
            gn.error("Unknown file format: {}".format(file_format))

        for meta_name in sample_meta_tb.columns:
            meta_output_name = "[M]{}".format(meta_name)

            sample_meta_dict = dict(zip(sample_ids, sample_meta_tb[meta_name].values.tolist()))

            gn.export(sample_meta_dict, meta_output_name, "sampleMeta")

            num_sample_values = 5
            sample_values = ", ".join(sample_meta_tb[meta_name].astype(str).values[0:num_sample_values].tolist())
            num_omitted_values = len(sample_meta_tb[meta_name]) - num_sample_values

            if num_omitted_values > 0:
                etc = ", ... and {} more entries".format(num_omitted_values)
            else:
                etc = ""

            meta_rows.append({
                'meta_name': meta_name,
                'sample_values': str(sample_values) + etc,
            })

    # meta_message = '\n'.join(
    #     "* Sample meta with name **{meta_name}** is accepted ({sample_values}).".format(**x) for x in meta_rows
    # )

    # gn.add_result(meta_message, "markdown")

    # gn.add_result({'columns': []}, 'table')

    # TODO: SAVE assay pickle

    print("Executing gn.commit",  flush=True, file=sys.stderr)
    gn.commit()
    print("Finished gn.commit",  flush=True, file=sys.stderr)


if __name__ == "__main__":
    main()
